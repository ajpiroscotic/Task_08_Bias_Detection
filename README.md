# Project Title: Bias Detection in LLM-Generated Syracuse Women’s Lacrosse Narratives

## Overview

This project designs, executes, and analyzes an experiment to detect biases in large language model (LLM) outputs using Syracuse Women’s Lacrosse 2023 player statistics. It focuses on how prompt variations influence the narratives generated by GPT-4, Claude, and Gemini.

## Repository Contents

- `experiment_design.py`: Generates all prompt variations based on hypothesis framing (H1: framing effect, H2: role context effect, H3: confirmation priming).  
- `run_experiment.py`: Executes queries against multiple LLMs, logs raw responses, and metadata.  
- `analyze_bias.py`: Performs sentiment analysis and quantitative summary of model outputs.  
- `validate_claims.py`: Validates factual model claims against ground truth player statistics.  
- `prompts/`: Directory containing prompt templates used for testing biases.    
- `REPORT.md`: Detailed experimental report in markdown format.  

## Prerequisites

- Python 3.8+  
- Install dependencies:  
